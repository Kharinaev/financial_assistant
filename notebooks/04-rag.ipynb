{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import json_repair\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VSE_GPT_API_KEY = \"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = VSE_GPT_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_df = pd.read_csv(\"/Users/alfa/Code/financial_assistant/data/interim/alfa_invest_advanced_paragraphs.csv\")\n",
    "beg_df = pd.read_csv(\"/Users/alfa/Code/financial_assistant/data/interim/alfa_invest_begginer_paragraphs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29 entries, 0 to 28\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   paragraph_id  29 non-null     object\n",
      " 1   article_id    29 non-null     object\n",
      " 2   heading       29 non-null     object\n",
      " 3   text          29 non-null     object\n",
      "dtypes: object(4)\n",
      "memory usage: 1.0+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38 entries, 0 to 37\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   paragraph_id  38 non-null     object\n",
      " 1   article_id    38 non-null     object\n",
      " 2   heading       38 non-null     object\n",
      " 3   text          38 non-null     object\n",
      "dtypes: object(4)\n",
      "memory usage: 1.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_df.info(), beg_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>heading</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIA_0000_0001</td>\n",
       "      <td>AIA_0000</td>\n",
       "      <td># **–ò–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã–µ –∏ —Ä–æ—Å—Å–∏–π—Å–∫–∏–µ –∞–∫—Ü–∏–∏**</td>\n",
       "      <td>**–ê–∫—Ü–∏—è** ‚Äî —ç—Ç–æ —Ü–µ–Ω–Ω–∞—è –±—É–º–∞–≥–∞, –ø–æ–∑–≤–æ–ª—è—é—â–∞—è –∏–Ω–≤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIA_0000_0002</td>\n",
       "      <td>AIA_0000</td>\n",
       "      <td># **–õ–∏—Å—Ç–∏–Ω–≥ —Ü–µ–Ω–Ω—ã—Ö –±—É–º–∞–≥**</td>\n",
       "      <td>–ö–æ–º–ø–∞–Ω–∏–∏, —á—å–∏ –∞–∫—Ü–∏–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –Ω–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–º—É –∫...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIA_0000_0003</td>\n",
       "      <td>AIA_0000</td>\n",
       "      <td># **–ê–∫—Ü–∏–∏, –≤–∫–ª—é—á—ë–Ω–Ω—ã–µ –≤ –∏–Ω–¥–µ–∫—Å**</td>\n",
       "      <td>**–ò–Ω–¥–µ–∫—Å—ã** ‚Äî —ç—Ç–æ –≤–∞–∂–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —Å–∏—Ç—É–∞—Ü–∏–∏ –Ω...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AIA_0000_0004</td>\n",
       "      <td>AIA_0000</td>\n",
       "      <td># **–†–∏—Å–∫–∏, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –ø–æ–∫—É–ø–∫–æ–π –∞–∫—Ü–∏–π –∏–Ω–æ—Å—Ç—Ä–∞–Ω...</td>\n",
       "      <td>–ò–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏ –∏ –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã–µ –±–∏—Ä–∂–∏ –ø–æ–¥—á–∏...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AIA_0001_0005</td>\n",
       "      <td>AIA_0001</td>\n",
       "      <td>–û–±–ª–∏–≥–∞—Ü–∏–∏ —Å –Ω–∏–∑–∫–∏–º –∫—Ä–µ–¥–∏—Ç–Ω—ã–º —Ä–µ–π—Ç–∏–Ω–≥–æ–º</td>\n",
       "      <td>**–û–±–ª–∏–≥–∞—Ü–∏—è** ‚Äî —ç—Ç–æ –¥–æ–ª–≥–æ–≤–∞—è —Ü–µ–Ω–Ω–∞—è –±—É–º–∞–≥–∞, –æ–±...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        chunk_id article_id  \\\n",
       "0  AIA_0000_0001   AIA_0000   \n",
       "1  AIA_0000_0002   AIA_0000   \n",
       "2  AIA_0000_0003   AIA_0000   \n",
       "3  AIA_0000_0004   AIA_0000   \n",
       "4  AIA_0001_0005   AIA_0001   \n",
       "\n",
       "                                             heading  \\\n",
       "0               # **–ò–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã–µ –∏ —Ä–æ—Å—Å–∏–π—Å–∫–∏–µ –∞–∫—Ü–∏–∏**   \n",
       "1                         # **–õ–∏—Å—Ç–∏–Ω–≥ —Ü–µ–Ω–Ω—ã—Ö –±—É–º–∞–≥**   \n",
       "2                   # **–ê–∫—Ü–∏–∏, –≤–∫–ª—é—á—ë–Ω–Ω—ã–µ –≤ –∏–Ω–¥–µ–∫—Å**   \n",
       "3  # **–†–∏—Å–∫–∏, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –ø–æ–∫—É–ø–∫–æ–π –∞–∫—Ü–∏–π –∏–Ω–æ—Å—Ç—Ä–∞–Ω...   \n",
       "4             –û–±–ª–∏–≥–∞—Ü–∏–∏ —Å –Ω–∏–∑–∫–∏–º –∫—Ä–µ–¥–∏—Ç–Ω—ã–º —Ä–µ–π—Ç–∏–Ω–≥–æ–º   \n",
       "\n",
       "                                                text  \n",
       "0  **–ê–∫—Ü–∏—è** ‚Äî —ç—Ç–æ —Ü–µ–Ω–Ω–∞—è –±—É–º–∞–≥–∞, –ø–æ–∑–≤–æ–ª—è—é—â–∞—è –∏–Ω–≤...  \n",
       "1  –ö–æ–º–ø–∞–Ω–∏–∏, —á—å–∏ –∞–∫—Ü–∏–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –Ω–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–º—É –∫...  \n",
       "2  **–ò–Ω–¥–µ–∫—Å—ã** ‚Äî —ç—Ç–æ –≤–∞–∂–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —Å–∏—Ç—É–∞—Ü–∏–∏ –Ω...  \n",
       "3  –ò–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏ –∏ –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã–µ –±–∏—Ä–∂–∏ –ø–æ–¥—á–∏...  \n",
       "4  **–û–±–ª–∏–≥–∞—Ü–∏—è** ‚Äî —ç—Ç–æ –¥–æ–ª–≥–æ–≤–∞—è —Ü–µ–Ω–Ω–∞—è –±—É–º–∞–≥–∞, –æ–±...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>heading</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIB_0000_0001</td>\n",
       "      <td>AIB_0000</td>\n",
       "      <td>–ß—Ç–æ —Ç–∞–∫–æ–µ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏?</td>\n",
       "      <td>–î–µ–Ω—å–≥–∏ –Ω—É–∂–Ω—ã, —á—Ç–æ–±—ã –∏—Ö —Ç—Ä–∞—Ç–∏—Ç—å. –≠—Ç–æ –ø–æ–Ω—è—Ç–Ω–æ. –ù...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIB_0000_0002</td>\n",
       "      <td>AIB_0000</td>\n",
       "      <td>## **–ß—Ç–æ —ç—Ç–æ –∑–∞ —á–∏—Å–ª–∞ –∏ –ø–æ—á–µ–º—É –≤–¥—Ä—É–≥ —Ç–∞–∫–æ–π —Ä–µ–∑...</td>\n",
       "      <td>üîê **–•—Ä–∞–Ω–∏–ª–∏ –¥–æ–º–∞** –ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ —Ç–æ, —á—Ç–æ –¥–µ–Ω—å–≥–∏ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIB_0001_0003</td>\n",
       "      <td>AIB_0001</td>\n",
       "      <td>–ì–¥–µ –∏ –≤–æ —á—Ç–æ –º–æ–∂–Ω–æ –∏–Ω–≤–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å?</td>\n",
       "      <td>–ü–ª–æ—â–∞–¥–∫–∞, –≥–¥–µ –∏–¥—ë—Ç —Ç–æ—Ä–≥–æ–≤–ª—è —Ü–µ–Ω–Ω—ã–º–∏ –±—É–º–∞–≥–∞–º–∏ ‚Äî...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AIB_0001_0004</td>\n",
       "      <td>AIB_0001</td>\n",
       "      <td># **–ö—Ç–æ —Ç–æ—Ä–≥—É–µ—Ç –Ω–∞ –±–∏—Ä–∂–µ?**</td>\n",
       "      <td>–ü—Ä–æ–¥–∞–≤—Ü–∞–º–∏ –Ω–∞ –±–∏—Ä–∂–µ –º–æ–≥—É—Ç –±—ã—Ç—å —Å–∞–º–∏ –∫–æ–º–ø–∞–Ω–∏–∏, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AIB_0001_0005</td>\n",
       "      <td>AIB_0001</td>\n",
       "      <td>### **–ß—Ç–æ –¥–µ–ª–∞–µ—Ç –±—Ä–æ–∫–µ—Ä:**</td>\n",
       "      <td>1. –û—Ç–∫—Ä—ã–≤–∞–µ—Ç –∏–Ω–≤–µ—Å—Ç–æ—Ä–∞–º [—Å—á–µ—Ç–∞](https://alfaba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        chunk_id article_id  \\\n",
       "0  AIB_0000_0001   AIB_0000   \n",
       "1  AIB_0000_0002   AIB_0000   \n",
       "2  AIB_0001_0003   AIB_0001   \n",
       "3  AIB_0001_0004   AIB_0001   \n",
       "4  AIB_0001_0005   AIB_0001   \n",
       "\n",
       "                                             heading  \\\n",
       "0                              –ß—Ç–æ —Ç–∞–∫–æ–µ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏?   \n",
       "1  ## **–ß—Ç–æ —ç—Ç–æ –∑–∞ —á–∏—Å–ª–∞ –∏ –ø–æ—á–µ–º—É –≤–¥—Ä—É–≥ —Ç–∞–∫–æ–π —Ä–µ–∑...   \n",
       "2                  –ì–¥–µ –∏ –≤–æ —á—Ç–æ –º–æ–∂–Ω–æ –∏–Ω–≤–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å?   \n",
       "3                        # **–ö—Ç–æ —Ç–æ—Ä–≥—É–µ—Ç –Ω–∞ –±–∏—Ä–∂–µ?**   \n",
       "4                         ### **–ß—Ç–æ –¥–µ–ª–∞–µ—Ç –±—Ä–æ–∫–µ—Ä:**   \n",
       "\n",
       "                                                text  \n",
       "0  –î–µ–Ω—å–≥–∏ –Ω—É–∂–Ω—ã, —á—Ç–æ–±—ã –∏—Ö —Ç—Ä–∞—Ç–∏—Ç—å. –≠—Ç–æ –ø–æ–Ω—è—Ç–Ω–æ. –ù...  \n",
       "1  üîê **–•—Ä–∞–Ω–∏–ª–∏ –¥–æ–º–∞** –ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ —Ç–æ, —á—Ç–æ –¥–µ–Ω—å–≥–∏ ...  \n",
       "2  –ü–ª–æ—â–∞–¥–∫–∞, –≥–¥–µ –∏–¥—ë—Ç —Ç–æ—Ä–≥–æ–≤–ª—è —Ü–µ–Ω–Ω—ã–º–∏ –±—É–º–∞–≥–∞–º–∏ ‚Äî...  \n",
       "3  –ü—Ä–æ–¥–∞–≤—Ü–∞–º–∏ –Ω–∞ –±–∏—Ä–∂–µ –º–æ–≥—É—Ç –±—ã—Ç—å —Å–∞–º–∏ –∫–æ–º–ø–∞–Ω–∏–∏, ...  \n",
       "4  1. –û—Ç–∫—Ä—ã–≤–∞–µ—Ç –∏–Ω–≤–µ—Å—Ç–æ—Ä–∞–º [—Å—á–µ—Ç–∞](https://alfaba...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze texts lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tokens_num = lambda text: len(enc.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_df['num_tokens'] = adv_df.text.apply(get_tokens_num)\n",
    "beg_df['num_tokens'] = beg_df.text.apply(get_tokens_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count      29.000000\n",
       " mean      973.896552\n",
       " std       637.543127\n",
       " min       187.000000\n",
       " 25%       577.000000\n",
       " 50%       797.000000\n",
       " 75%      1193.000000\n",
       " max      3493.000000\n",
       " Name: num_tokens, dtype: float64,\n",
       " count     38.000000\n",
       " mean     280.973684\n",
       " std      178.128027\n",
       " min       53.000000\n",
       " 25%      139.000000\n",
       " 50%      231.000000\n",
       " 75%      376.000000\n",
       " max      768.000000\n",
       " Name: num_tokens, dtype: float64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_df.num_tokens.describe(), beg_df.num_tokens.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunkize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=256, chunk_overlap=16, length_function=get_tokens_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['–û–±–ª–∏–≥–∞—Ü–∏–∏ –º–æ–∂–Ω–æ –ø—Ä–∏–æ–±—Ä–µ—Å—Ç–∏ –Ω–∞–ø—Ä—è–º—É—é —É —ç–º–∏—Ç–µ–Ω—Ç–∞ –ø—Ä–∏ —Ä–∞–∑–º–µ—â–µ–Ω–∏–∏ –≤—ã–ø—É—Å–∫–∞ –∏–ª–∏ —É –¥—Ä—É–≥–∏—Ö –∏–Ω–≤–µ—Å—Ç–æ—Ä–æ–≤ –Ω–∞ —Ñ–æ–Ω–¥–æ–≤–æ–º —Ä—ã–Ω–∫–µ, –∏–ª–∏ –Ω–∞ –≤–Ω–µ–±–∏—Ä–∂–µ–≤–æ–º —Ä—ã–Ω–∫–µ.',\n",
       " '–ü—Ä–∏ –ø–æ–∫—É–ø–∫–µ –æ–±–ª–∏–≥–∞—Ü–∏–π –∏–Ω–≤–µ—Å—Ç–æ—Ä –∑–∞–ø–ª–∞—Ç–∏—Ç –∑–∞ –Ω–µ—ë –Ω–æ–º–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–æ–∏–º–æ—Å—Ç—å ‚Äî –µ—Å–ª–∏ –ø–æ–∫—É–ø–∞–µ—Ç –Ω–∞–ø—Ä—è–º—É—é —É —ç–º–∏—Ç–µ–Ω—Ç–∞ ‚Äî –∏–ª–∏ –±–∏—Ä–∂–µ–≤—É—é —Ü–µ–Ω—É, –µ—Å–ª–∏ –ø—Ä–∏–æ–±—Ä–µ—Ç–∞–µ—Ç –µ—ë –Ω–∞ –±–∏—Ä–∂–µ. –¶–µ–Ω—ã –æ–±–ª–∏–≥–∞—Ü–∏–π —É–∫–∞–∑—ã–≤–∞—é—Ç—Å—è –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö –æ—Ç –Ω–æ–º–∏–Ω–∞–ª–∞, –∞ –æ–Ω –≤—Å–µ–≥–¥–∞ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç 1000 –µ–¥–∏–Ω–∏—Ü –≤–∞–ª—é—Ç—ã –≤—ã–ø—É—Å–∫–∞. –ù–∞–ø—Ä–∏–º–µ—Ä, —Ü–µ–Ω–∞ —Ä—É–±–ª—ë–≤–æ–π –æ–±–ª–∏–≥–∞—Ü–∏–∏ 98,6% –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –∑–∞ –±—É–º–∞–≥—É –Ω—É–∂–Ω–æ –∑–∞–ø–ª–∞—Ç–∏—Ç—å 98,6% –æ—Ç –Ω–æ–º–∏–Ω–∞–ª–∞, —Ç–æ –µ—Å—Ç—å 986 —Ä—É–±–ª–µ–π. –û–±–ª–∏–≥–∞—Ü–∏–∏ –º–æ–≥—É—Ç –≤—ã–ø—É—Å–∫–∞—Ç—å—Å—è –Ω–µ —Ç–æ–ª—å–∫–æ –≤ —Ä—É–±–ª—è—Ö, —ç–º–∏—Ç–µ–Ω—Ç –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –≤–∞–ª—é—Ç—É, –≤ –∫–æ—Ç–æ—Ä–æ–π –µ–º—É –Ω—É–∂–Ω—ã —Å—Ä–µ–¥—Å—Ç–≤–∞. –ò —ç—Ç–æ –º–æ–≥—É—Ç –±—ã—Ç—å –¥–æ–ª–ª–∞—Ä—ã, –µ–≤—Ä–æ, —é–∞–Ω–∏ –∏ –¥—Ä—É–≥–∏–µ –≤–∞–ª—é—Ç—ã ‚Äî –≤–∞–ª—é—Ç–Ω—ã–µ',\n",
       " '—é–∞–Ω–∏ –∏ –¥—Ä—É–≥–∏–µ –≤–∞–ª—é—Ç—ã ‚Äî –≤–∞–ª—é—Ç–Ω—ã–µ –æ–±–ª–∏–≥–∞—Ü–∏–∏ —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–æ –Ω–∞–∑—ã–≤–∞—é—Ç—Å—è –µ–≤—Ä–æ–æ–±–ª–∏–≥–∞—Ü–∏—è–º–∏, –¥–∞–∂–µ –µ—Å–ª–∏ –æ–Ω–∏ –≤ –¥—Ä—É–≥–∏—Ö –≤–∞–ª—é—Ç–∞—Ö.',\n",
       " '–û—Ü–µ–Ω–∏–≤–∞—è –≤—ã–≥–æ–¥—ã –æ—Ç —Å–¥–µ–ª–∫–∏ —Å –æ–±–ª–∏–≥–∞—Ü–∏—è–º–∏, –∏–Ω–≤–µ—Å—Ç–æ—Ä—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —Å–º–æ—Ç—Ä—è—Ç –Ω–∞ —Ä–∞–∑–º–µ—Ä –∫—É–ø–æ–Ω–Ω—ã—Ö –≤—ã–ø–ª–∞—Ç –ø–æ –Ω–∏–º, –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π –∫—É–ø–æ–Ω–Ω—ã–π –¥–æ—Ö–æ–¥ (–ù–ö–î) –∏ —Å—Ä–æ–∫ –ø–æ–≥–∞—à–µ–Ω–∏—è ‚Äî –≤—Å—ë —ç—Ç–æ –≤–ª–∏—è–µ—Ç –Ω–∞ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å —Ç–∞–∫–æ–π –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏. –ö—É–ø–æ–Ω –∏–¥—ë—Ç –≤ –¥–æ—Ö–æ–¥ –∏–Ω–≤–µ—Å—Ç–æ—Ä–∞, –≤–µ–¥—å —ç–º–∏—Ç–µ–Ω—Ç –ø–µ—Ä–µ—á–∏—Å–ª—è–µ—Ç –∑–∞—Ä–∞–Ω–µ–µ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ —Å—É–º–º—ã –≤ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞—Ç—ã —Ç–æ–º—É, –∫—Ç–æ –Ω–∞ —ç—Ç—É –¥–∞—Ç—É –≤–ª–∞–¥–µ–µ—Ç –æ–±–ª–∏–≥–∞—Ü–∏–µ–π. –ü–æ—ç—Ç–æ–º—É –ø—Ä–∏ —Å–¥–µ–ª–∫–∞—Ö —Å –æ–±–ª–∏–≥–∞—Ü–∏—è–º–∏ –ø–æ–∫—É–ø–∞—Ç–µ–ª—å –ø–µ—Ä–µ—á–∏—Å–ª—è–µ—Ç –ø—Ä–æ–¥–∞–≤—Ü—É –Ω–µ —Ç–æ–ª—å–∫–æ —Å—Ç–æ–∏–º–æ—Å—Ç—å —Å–∞–º–æ–π –±—É–º–∞–≥–∏, –Ω–æ –∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π –∫—É–ø–æ–Ω–Ω—ã–π –¥–æ—Ö–æ–¥ ‚Äî –ø—Ä–∏—á–∏—Ç–∞—é—â—É—é—Å—è –ø—Ä–æ–¥–∞–≤—Ü—É —á–∞—Å—Ç—å –ø—Ä–µ–¥—Å—Ç–æ—è—â–µ–π –∫—É–ø–æ–Ω–Ω–æ–π –≤—ã–ø–ª–∞—Ç—ã, –∫–æ—Ç–æ—Ä–∞—è –Ω–∞–∫–æ–ø–∏–ª–∞—Å—å —Å –º–æ–º–µ–Ω—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π',\n",
       " '–∫–æ—Ç–æ—Ä–∞—è –Ω–∞–∫–æ–ø–∏–ª–∞—Å—å —Å –º–æ–º–µ–Ω—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π –≤—ã–ø–ª–∞—Ç—ã –∫—É–ø–æ–Ω–∞.',\n",
       " '–ï—Å–ª–∏ –∏–Ω–≤–µ—Å—Ç–æ—Ä –ø—Ä–∏–æ–±—Ä–µ—Ç–∞–µ—Ç –æ–±–ª–∏–≥–∞—Ü–∏—é –Ω–∞ –≤–Ω–µ–±–∏—Ä–∂–µ–≤–æ–º —Ä—ã–Ω–∫–µ, —Ç–æ —Ü–µ–Ω–∞ —Ç–∞–∫–æ–π —Å–¥–µ–ª–∫–∏ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Ä—ã–Ω–æ—á–Ω–æ–π, –∞ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –ø–æ —Ñ–æ—Ä–º—É–ª–µ:\\n*(—Ü–µ–Ω–∞ –ø–æ–∫—É–ø–∫–∏ √ó –Ω–æ–º–∏–Ω–∞–ª –æ–±–ª–∏–≥–∞—Ü–∏–∏ + –ù–ö–î) √ó –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±—É–º–∞–≥ + –∫–æ–º–∏—Å—Å–∏—è –±—Ä–æ–∫–µ—Ä–∞ + –∫–æ–º–∏—Å—Å–∏—è –¥–µ–ø–æ–∑–∏—Ç–∞—Ä–∏—è*']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter.split_text(adv_df.iloc[5]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[61, 252, 56, 255, 23, 107]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[get_tokens_num(c) for c in splitter.split_text(adv_df.iloc[5]['text'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build all chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chunks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c00a815370a8474798d739a690afd831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx, row in tqdm(adv_df.iterrows()):\n",
    "    chunks = splitter.split_text(row.text)\n",
    "    for chunk_id, chunk in enumerate(chunks):\n",
    "        all_chunks.append(\n",
    "            Document(\n",
    "                page_content=chunk,\n",
    "                metadata={\n",
    "                    \"chunk_id\" : chunk_id,\n",
    "                    \"paragraph_id\" : row.paragraph_id,\n",
    "                    \"article_id\" : row.article_id\n",
    "                }\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in beg_df.iterrows():\n",
    "    chunks = splitter.split_text(row.text)\n",
    "    for chunk_id, chunk in enumerate(chunks):\n",
    "        all_chunks.append(\n",
    "            Document(\n",
    "                page_content=chunk,\n",
    "                metadata={\n",
    "                    \"chunk_id\" : chunk_id,\n",
    "                    \"paragraph_id\" : row.paragraph_id,\n",
    "                    \"article_id\" : row.article_id\n",
    "                }\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='–ï—Å–ª–∏ –ø–∞–¥–∞–µ—Ç —Ü–µ–Ω–∞ –±–∞–∑–æ–≤–æ–≥–æ –∞–∫—Ç–∏–≤–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä –∞–∫—Ü–∏–π, –¥–µ—à–µ–≤–µ–µ—Ç –∏ —Ñ—å—é—á–µ—Ä—Å –Ω–∞ –Ω–∏—Ö. –ï–≥–æ –≤–ª–∞–¥–µ–ª–µ—Ü –Ω–µ—Å—ë—Ç —É–±—ã—Ç–æ–∫ –∏–∑-–∑–∞ —Å–ø–∏—Å–∞–Ω–∏—è –≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–æ–π –º–∞—Ä–∂–∏ –∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≥–∞—Ä–∞–Ω—Ç–∏–π–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è. –ü—Ä–∏ –Ω–µ—Ö–≤–∞—Ç–∫–µ —Å—Ä–µ–¥—Å—Ç–≤ –±—Ä–æ–∫–µ—Ä –ø—Ä–µ–¥—É–ø—Ä–µ–¥–∏—Ç, —á—Ç–æ –Ω–∞–¥–æ –ø–æ–ø–æ–ª–Ω–∏—Ç—å —Å—á—ë—Ç. –ï—Å–ª–∏ —ç—Ç–æ–≥–æ –Ω–µ —Å–¥–µ–ª–∞—Ç—å, –¥–∞–∂–µ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ –ø–æ–∑–∏—Ü–∏–∏ –±–∞–ª–∞–Ω—Å —Å—á—ë—Ç–∞ –º–æ–∂–µ—Ç —Å—Ç–∞—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º. –ï—Å–ª–∏ —Ü–µ–Ω–∞ –∞–∫—Ç–∏–≤–∞ —Ä–µ–∑–∫–æ —É–ø–∞–ª–∞, –∞ –Ω–∞ —Å—á—ë—Ç–µ –Ω–µ—Ç –¥–µ–Ω–µ–≥ –¥–ª—è –ø–æ–ø–æ–ª–Ω–µ–Ω–∏—è –≥–∞—Ä–∞–Ω—Ç–∏–π–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –∏–ª–∏ –æ–±—Ä–∞–∑–æ–≤–∞–ª–∞—Å—å –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å ‚Äî –±—Ä–æ–∫–µ—Ä –∏–º–µ–µ—Ç –ø—Ä–∞–≤–æ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–∫—Ä—ã—Ç—å –ø–æ–∑–∏—Ü–∏—é –ø–æ —Ñ—å—é—á–µ—Ä—Å—É.', metadata={'chunk_id': 5, 'paragraph_id': 'AIA_0004_0016', 'article_id': 'AIA_0004'})"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_chunks[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\", \n",
    "    openai_api_base = \"https://api.vsegpt.ru/v1/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    }
   ],
   "source": [
    "db = FAISS.from_documents(all_chunks, embedding_model)\n",
    "db.save_local(\"/Users/alfa/Code/financial_assistant/data/processed/docs_db_index\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector DB search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"\"\"\n",
    "–õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å –∞–∫—Ü–∏–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏–∑—É–µ—Ç\n",
    "–ê) –°–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∏–Ω–≤–µ—Å—Ç–æ—Ä–∞ –ø—Ä–æ–¥–∞—Ç—å –∞–∫—Ü–∏—é —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –¥–ª—è –Ω–µ–≥–æ –ø–æ—Ç–µ—Ä—è–º–∏ –≤ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Å—Ä–æ–∫. \n",
    "–ë) –†–∞–∑–Ω–∏—Ü—É —Ü–µ–Ω—ã —Ç–∞–∫–æ–π –∞–∫—Ü–∏–∏ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Ç–æ—Ä–≥–æ–≤—ã—Ö –ø–ª–æ—â–∞–¥–∫–∞—Ö. \n",
    "–í) –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ–≥–∞—à–µ–Ω–∏—è –∞–∫—Ü–∏–∏ –∫–æ–º–ø–∞–Ω–∏–µ–π ‚Äì —ç–º–∏—Ç–µ–Ω—Ç–æ–º. \n",
    "–ì) –ù–∏ –æ–¥–∏–Ω –∏–∑ –æ—Ç–≤–µ—Ç–æ–≤ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='**–õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å** ‚Äî —ç—Ç–æ —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–π —Ç–µ—Ä–º–∏–Ω, –ø–æ–∫–∞–∑—ã–≤–∞—é—â–∏–π –∫–∞–∫ –±—ã—Å—Ç—Ä–æ –∞–∫—Ç–∏–≤ (–∞–∫—Ü–∏–∏) –º–æ–∂–Ω–æ –ø—Ä–æ–¥–∞—Ç—å –ø–æ —Ü–µ–Ω–µ, –±–ª–∏–∑–∫–æ–π –∫ —Ä—ã–Ω–æ—á–Ω–æ–π, —Ç. –µ. —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –ø–æ—Ç–µ—Ä—è–º–∏ –¥–ª—è –∏–Ω–≤–µ—Å—Ç–æ—Ä–∞. –ï—Å–ª–∏ —Å–ø—Ä–æ—Å –Ω–∞ –ø–æ–∫—É–ø–∫—É –∏ –ø—Ä–æ–¥–∞–∂—É –∞–∫—Ç–∏–≤–∞ –µ—Å—Ç—å –≤—Å–µ–≥–¥–∞ –∏ —Å –Ω–∏–º –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –º–Ω–æ–≥–æ —Å–¥–µ–ª–æ–∫, —Ç–∞–∫–æ–π –∞–∫—Ç–∏–≤ –Ω–∞–∑—ã–≤–∞—é—Ç –≤—ã—Å–æ–∫–æ–ª–∏–∫–≤–∏–¥–Ω—ã–º.\\n**–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å** (–∞–Ω–≥–ª. volatility) ‚Äî —ç—Ç–æ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ—Ä–º–∏–Ω —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏–∑—É–µ—Ç –∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç—å –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è –≤ —Ç–µ—á–µ–Ω–∏–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏. –ü—Ä–∏–º–µ–Ω–∏—Ç–µ–ª—å–Ω–æ –∫ –∞–∫—Ü–∏—è–º –≥–æ–≤–æ—Ä—è—Ç, —á—Ç–æ –æ–Ω–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã, –µ—Å–ª–∏ –∏—Ö —Ü–µ–Ω–∞ –º–µ–Ω—è–µ—Ç—Å—è —Å–∏–ª—å–Ω–µ–µ –∏ –±—ã—Å—Ç—Ä–µ–µ, —á–µ–º —É –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –¥—Ä—É–≥–∏—Ö –∞–∫—Ü–∏–π.', metadata={'chunk_id': 4, 'paragraph_id': 'AIA_0000_0002', 'article_id': 'AIA_0000'}),\n",
       " Document(page_content='-\\n–ê–∫—Ü–∏—è, –Ω–µ –≤–∫–ª—é—á—ë–Ω–Ω–∞—è –≤ –∫–æ—Ç–∏—Ä–æ–≤–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫, –∫–∞–∫ –ø—Ä–∞–≤–∏–ª–æ, –º–µ–Ω–µ–µ –ª–∏–∫–≤–∏–¥–Ω–∞. –ê –∑–Ω–∞—á–∏—Ç, —Ä–∏—Å–∫–∏ –Ω–µ –Ω–∞–π—Ç–∏ –ø—Ä–æ–¥–∞–≤—Ü–∞ –∏–ª–∏ –ø–æ–∫—É–ø–∞—Ç–µ–ª—è –≤—ã—Å–æ–∫–∏.\\n-\\n–ü—Ä–∏ —ç—Ç–æ–º –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –≤ –∫–æ—Ç–∏—Ä–æ–≤–∞–ª—å–Ω–æ–º —Å–ø–∏—Å–∫–µ –≤–æ–≤—Å–µ –Ω–µ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ —Ü–µ–Ω–∞ —Ç–∞–∫–æ–π –∞–∫—Ü–∏–∏ –±—É–¥–µ—Ç –Ω–∏–∂–µ, —á–µ–º —Ü–µ–Ω—ã –∞–∫—Ü–∏–π –∏–∑ –∫–æ—Ç–∏—Ä–æ–≤–∞–ª—å–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞.', metadata={'chunk_id': 6, 'paragraph_id': 'AIA_0000_0002', 'article_id': 'AIA_0000'}),\n",
       " Document(page_content='–í —Å–ø–∏—Å–æ–∫ –ø–µ—Ä–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è –Ω–µ —Å–º–æ–∂–µ—Ç –ø–æ–ø–∞—Å—Ç—å –∫–æ–º–ø–∞–Ω–∏—è, —Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è –º–µ–Ω—å—à–µ —Ç—Ä—ë—Ö –ª–µ—Ç –∏–ª–∏ –±–µ–∑ —Ç—Ä—ë—Ö–ª–µ—Ç–Ω–µ–π –æ—Ç—á—ë—Ç–Ω–æ—Å—Ç–∏ –ø–æ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º. –ê –¥–ª—è –∫–æ–º–ø–∞–Ω–∏–π —Ç—Ä–µ—Ç—å–µ–≥–æ —É—Ä–æ–≤–Ω—è –Ω–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –Ω–∏ –ø–æ –¥–∞—Ç–µ –∏—Ö —Å–æ–∑–¥–∞–Ω–∏—è, –Ω–∏ –ø–æ –æ—Ç—á—ë—Ç–Ω–æ—Å—Ç–∏, –Ω–∏ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∞–∫—Ü–∏–π –≤ –æ–±—Ä–∞—â–µ–Ω–∏–∏. –ü–æ—ç—Ç–æ–º—É –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å –∏—Ö –∞–∫—Ü–∏—è–º–∏ –±–æ–ª–µ–µ —Ä–∏—Å–∫–æ–≤–∞–Ω–Ω—ã.\\n–ò–Ω–≤–µ—Å—Ç–æ—Ä—É –Ω—É–∂–Ω–æ –ø–æ–º–Ω–∏—Ç—å, —á—Ç–æ –∞–∫—Ü–∏–∏ –∫–æ–º–ø–∞–Ω–∏–π –Ω–µ –∏–∑ –∫–æ—Ç–∏—Ä–æ–≤–∞–ª—å–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ –±–∏—Ä–∂–∏ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –º–µ–Ω—å—à–µ–π –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å—é –∏ –±–æ–ª—å—à–µ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å—é. –û–±—ä—è—Å–Ω–∏–º, —á—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç.', metadata={'chunk_id': 3, 'paragraph_id': 'AIA_0000_0002', 'article_id': 'AIA_0000'})]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search(user_query, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "VSE_GPT_API_KEY = \"\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=VSE_GPT_API_KEY,\n",
    "    base_url=\"https://api.vsegpt.ru/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/alfa/Code/financial_assistant/data/interim/test_qual_investor/questions.json', 'r') as f:\n",
    "    questions = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1.4',\n",
       " 'question': '–õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å –∞–∫—Ü–∏–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏–∑—É–µ—Ç',\n",
       " 'options': [{'letter': '–ê',\n",
       "   'option_text': '–°–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∏–Ω–≤–µ—Å—Ç–æ—Ä–∞ –ø—Ä–æ–¥–∞—Ç—å –∞–∫—Ü–∏—é —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –¥–ª—è –Ω–µ–≥–æ –ø–æ—Ç–µ—Ä—è–º–∏ –≤ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Å—Ä–æ–∫.'},\n",
       "  {'letter': '–ë',\n",
       "   'option_text': '–†–∞–∑–Ω–∏—Ü—É —Ü–µ–Ω—ã —Ç–∞–∫–æ–π –∞–∫—Ü–∏–∏ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Ç–æ—Ä–≥–æ–≤—ã—Ö –ø–ª–æ—â–∞–¥–∫–∞—Ö.'},\n",
       "  {'letter': '–í',\n",
       "   'option_text': '–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ–≥–∞—à–µ–Ω–∏—è –∞–∫—Ü–∏–∏ –∫–æ–º–ø–∞–Ω–∏–µ–π ‚Äì —ç–º–∏—Ç–µ–Ω—Ç–æ–º.'},\n",
       "  {'letter': '–ì',\n",
       "   'option_text': '–ù–∏ –æ–¥–∏–Ω –∏–∑ –æ—Ç–≤–µ—Ç–æ–≤ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º.'}],\n",
       " 'answer': '–ê',\n",
       " 'chapter': 1}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/alfa/Code/financial_assistant/data/interim/test_qual_investor/chapters.json', 'r') as f:\n",
    "    chapters = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': '–ü–æ–∫—É–ø–∫–∞ –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã—Ö –∞–∫—Ü–∏–π',\n",
       " '2': '–ê–∫—Ü–∏–∏, –Ω–µ –≤–∫–ª—é—á–µ–Ω–Ω—ã–µ –≤ –∫–æ—Ç–∏—Ä–æ–≤–∞–ª—å–Ω—ã–µ —Å–ø–∏—Å–∫–∏',\n",
       " '3': '–î–æ–ø—É—Å–∫ –∫ –Ω–µ–æ–±–µ—Å–ø–µ—á–µ–Ω–Ω—ã–º —Å–¥–µ–ª–∫–∞–º (–º–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–∞—è —Ç–æ—Ä–≥–æ–≤–ª—è)',\n",
       " '4': '–ó–∞–∫–ª—é—á–µ–Ω–∏–µ –¥–æ–≥–æ–≤–æ—Ä–æ–≤ –†–ï–ü–û',\n",
       " '5': '–û–ø—Ü–∏–æ–Ω—ã, —Ñ—å—é—á–µ—Ä—Å—ã, –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã',\n",
       " '6': '–°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –æ–±–ª–∏–≥–∞—Ü–∏–∏',\n",
       " '7': '–ü–∞–∏ –∑–∞–∫—Ä—ã—Ç—ã—Ö –ø–∞–µ–≤—ã—Ö –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã—Ö —Ñ–æ–Ω–¥–æ–≤ (–ó–ü–ò–§)',\n",
       " '8': '–û–±–ª–∏–≥–∞—Ü–∏–∏ —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö —ç–º–∏—Ç–µ–Ω—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–º –Ω–µ –ø—Ä–∏—Å–≤–æ–µ–Ω —Ä–µ–π—Ç–∏–Ω–≥ –∏–ª–∏ –æ–Ω –Ω–∏–∂–µ —É—Ä–æ–≤–Ω—è',\n",
       " '9': '–û–±–ª–∏–≥–∞—Ü–∏–∏ –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã—Ö —ç–º–∏—Ç–µ–Ω—Ç–æ–≤ –≤ –≤–∞–ª—é—Ç–µ (–µ–≤—Ä–æ–æ–±–ª–∏–≥–∞—Ü–∏–∏) –∫–æ—Ç–æ—Ä—ã–º –Ω–µ –ø—Ä–∏—Å–≤–æ–µ–Ω —Ä–µ–π—Ç–∏–Ω–≥ –∏–ª–∏ –æ–Ω –Ω–∏–∂–µ –Ω—É–∂–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è',\n",
       " '10': '–û–±–ª–∏–≥–∞—Ü–∏–∏ —Å–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–º –¥–æ—Ö–æ–¥–æ–º',\n",
       " '11': '–í–æ–ø—Ä–æ—Å—ã –¥–ª—è –¥–æ–ø—É—Å–∫–∞ –∫ –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã–º ETF'}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are qualified financial and investment assistant. \n",
      "Provide helpful answers to any question.  \n",
      "Stricly follow user instructions.  \n"
     ]
    }
   ],
   "source": [
    "with open(\"/Users/alfa/Code/financial_assistant/artifacts/prompts/system_v1.md\", \"r\") as f:\n",
    "    system_prompt = f.read()\n",
    "\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/alfa/Code/financial_assistant/artifacts/prompts/rag_v1.md\", \"r\") as f:\n",
    "    prompt_template = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instructions ###\n",
      "\n",
      "Answer the multiple-choice ###Question### about Russian invest market based on ###Context###.\n",
      "Follow ###Asnwer Format###.\n",
      "\n",
      "\n",
      "### Answer Format ###\n",
      "{{\n",
      "    \"reasoning\" : \"provide your brief (1-2 sentences) reasoning here\",\n",
      "    \"answer\": \"–ë\" # one of the first 4 cyrillyc letters: \"–ê\", \"–ë\", \"–í\" or \"–ì\"\n",
      "}}\n",
      "\n",
      "### Context ###\n",
      "{context}\n",
      "\n",
      "### Question ###\n",
      "{question}\n",
      "\n",
      "{option_1}\n",
      "{option_2}\n",
      "{option_3}\n",
      "{option_4}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rag_response(\n",
    "    question_dict : Dict, \n",
    "    prompt_template: str, \n",
    "    system_prompt: str, \n",
    "    db : FAISS,\n",
    "    model=\"openai/gpt-4o-2024-11-20\",\n",
    "    sampling_params: Dict = {\n",
    "        \"max_tokens\": 512,\n",
    "        \"temperature\": 0.5,\n",
    "        \"top_p\": 0.9\n",
    "    }\n",
    "):\n",
    "    \n",
    "    options = [\n",
    "        opt[\"letter\"] + '. ' + opt[\"option_text\"]\n",
    "        for opt in question_dict[\"options\"]\n",
    "    ]\n",
    "\n",
    "    question_with_options_text = '\\n'.join([question_dict['question']] + options)\n",
    "\n",
    "    top_docs = db.similarity_search(question_with_options_text, 3)\n",
    "    top_docs_texts = [f\"{i}. {doc.page_content}\" for i, doc in enumerate(top_docs)]\n",
    "    context = '\\n'.join(top_docs_texts)\n",
    "\n",
    "    prompt = prompt_template.format(\n",
    "        context=context,\n",
    "        question=question_dict['question'], \n",
    "        option_1=options[0],\n",
    "        option_2=options[1],\n",
    "        option_3=options[2], \n",
    "        option_4=options[3],\n",
    "    )\n",
    "\n",
    "    # return prompt\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": \"{\"}\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        **sampling_params\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ae1fe5be194498af393ef235504eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "responses = []\n",
    "for question_dict in tqdm(questions):\n",
    "    response = get_rag_response(\n",
    "        question_dict,\n",
    "        prompt_template,\n",
    "        system_prompt,\n",
    "        db,\n",
    "        model=\"openai/gpt-4o-mini\"\n",
    "    )\n",
    "    responses.append(response)\n",
    "    try:\n",
    "        response_text =  response.choices[0].message.content\n",
    "        if '{' not in response_text[:5]:\n",
    "            response_text = '{' + response_text\n",
    "        response_dict = json_repair.loads(response_text)\n",
    "\n",
    "        results.append(\n",
    "            question_dict | {\n",
    "                \"llm_answer\" : response_dict[\"answer\"],\n",
    "                \"llm_reasoning\" : response_dict[\"reasoning\"]\n",
    "            }\n",
    "        )\n",
    "    except Exception as e:\n",
    "        results.append({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 44 entries, 1.4 to 11.7\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   question       44 non-null     object\n",
      " 1   options        44 non-null     object\n",
      " 2   answer         44 non-null     object\n",
      " 3   chapter        44 non-null     int64 \n",
      " 4   llm_answer     44 non-null     object\n",
      " 5   llm_reasoning  44 non-null     object\n",
      " 6   correct        44 non-null     int64 \n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 2.8+ KB\n"
     ]
    }
   ],
   "source": [
    "res_df = pd.DataFrame(results).set_index(\"id\")\n",
    "res_df['correct'] = (res_df.answer == res_df.llm_answer).astype(int)\n",
    "res_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>options</th>\n",
       "      <th>answer</th>\n",
       "      <th>chapter</th>\n",
       "      <th>llm_answer</th>\n",
       "      <th>llm_reasoning</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.4</th>\n",
       "      <td>–õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å –∞–∫—Ü–∏–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏–∑—É–µ—Ç</td>\n",
       "      <td>[{'letter': '–ê', 'option_text': '–°–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∏...</td>\n",
       "      <td>–ê</td>\n",
       "      <td>1</td>\n",
       "      <td>–ê</td>\n",
       "      <td>–õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å –∞–∫—Ü–∏–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ –±—ã—Å—Ç—Ä–æ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5</th>\n",
       "      <td>–ß—Ç–æ –∏–∑ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω–æ–≥–æ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Ä–∏—Å–∫–æ–º –ø–æ –ø—Ä...</td>\n",
       "      <td>[{'letter': '–ê', 'option_text': '–†–∏—Å–∫ –∏–∑–º–µ–Ω–µ–Ω–∏...</td>\n",
       "      <td>–ê</td>\n",
       "      <td>1</td>\n",
       "      <td>–ê</td>\n",
       "      <td>–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Å—É–≤–µ—Ä–µ–Ω–Ω–æ–≥–æ —Ä–µ–π—Ç–∏–Ω–≥–∞ –†–æ—Å—Å–∏–∏ –Ω–µ –≤–ª–∏—è–µ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.6</th>\n",
       "      <td>–í —Ñ–æ–Ω–¥–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å, —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º—ã–π –±–∏—Ä–∂–µ–π, –≤–∫–ª—é...</td>\n",
       "      <td>[{'letter': '–ê', 'option_text': '–í—Å–µ –∞–∫—Ü–∏–∏, –¥–æ...</td>\n",
       "      <td>–ë</td>\n",
       "      <td>1</td>\n",
       "      <td>–ë</td>\n",
       "      <td>–ò–Ω–¥–µ–∫—Å –≤–∫–ª—é—á–∞–µ—Ç –∞–∫—Ü–∏–∏ —Ç–æ–ª—å–∫–æ —Ç–µ—Ö —ç–º–∏—Ç–µ–Ω—Ç–æ–≤, –∫–æ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.7</th>\n",
       "      <td>–í —Å–ª—É—á–∞–µ, –µ—Å–ª–∏ –í—ã –∫—É–ø–∏–ª–∏ –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—É—é –∞–∫—Ü–∏—é –∑–∞ ...</td>\n",
       "      <td>[{'letter': '–ê', 'option_text': '500 —Ä—É–±–ª–µ–π.'}...</td>\n",
       "      <td>–í</td>\n",
       "      <td>1</td>\n",
       "      <td>–í</td>\n",
       "      <td>–ü—Ä–∏ –ø—Ä–æ–¥–∞–∂–µ –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω–æ–π –∞–∫—Ü–∏–∏ –¥–æ—Ö–æ–¥ –≤ —Ä—É–±–ª—è—Ö —Ä...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.4</th>\n",
       "      <td>–í—ã –ø–æ–ª—É—á–∏–ª–∏ —É–±—ã—Ç–∫–∏ –æ—Ç —Å–æ–≤–µ—Ä—à–µ–Ω–∏—è —Å–¥–µ–ª–æ–∫ —Å –∞–∫—Ü–∏...</td>\n",
       "      <td>[{'letter': '–ê', 'option_text': '–ù–µ—Ç, –Ω–µ –≤–æ–∑–º–µ...</td>\n",
       "      <td>–ê</td>\n",
       "      <td>2</td>\n",
       "      <td>–ê</td>\n",
       "      <td>–í –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —Ç–æ—Ä–≥–æ–≤–ª–∏ –∞–∫—Ü–∏—è–º–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "id                                                       \n",
       "1.4                    –õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å –∞–∫—Ü–∏–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏–∑—É–µ—Ç   \n",
       "1.5  –ß—Ç–æ –∏–∑ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω–æ–≥–æ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Ä–∏—Å–∫–æ–º –ø–æ –ø—Ä...   \n",
       "1.6  –í —Ñ–æ–Ω–¥–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å, —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º—ã–π –±–∏—Ä–∂–µ–π, –≤–∫–ª—é...   \n",
       "1.7  –í —Å–ª—É—á–∞–µ, –µ—Å–ª–∏ –í—ã –∫—É–ø–∏–ª–∏ –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—É—é –∞–∫—Ü–∏—é –∑–∞ ...   \n",
       "2.4  –í—ã –ø–æ–ª—É—á–∏–ª–∏ —É–±—ã—Ç–∫–∏ –æ—Ç —Å–æ–≤–µ—Ä—à–µ–Ω–∏—è —Å–¥–µ–ª–æ–∫ —Å –∞–∫—Ü–∏...   \n",
       "\n",
       "                                               options answer  chapter  \\\n",
       "id                                                                       \n",
       "1.4  [{'letter': '–ê', 'option_text': '–°–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∏...      –ê        1   \n",
       "1.5  [{'letter': '–ê', 'option_text': '–†–∏—Å–∫ –∏–∑–º–µ–Ω–µ–Ω–∏...      –ê        1   \n",
       "1.6  [{'letter': '–ê', 'option_text': '–í—Å–µ –∞–∫—Ü–∏–∏, –¥–æ...      –ë        1   \n",
       "1.7  [{'letter': '–ê', 'option_text': '500 —Ä—É–±–ª–µ–π.'}...      –í        1   \n",
       "2.4  [{'letter': '–ê', 'option_text': '–ù–µ—Ç, –Ω–µ –≤–æ–∑–º–µ...      –ê        2   \n",
       "\n",
       "    llm_answer                                      llm_reasoning  correct  \n",
       "id                                                                          \n",
       "1.4          –ê  –õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å –∞–∫—Ü–∏–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ –±—ã—Å—Ç—Ä–æ...        1  \n",
       "1.5          –ê  –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Å—É–≤–µ—Ä–µ–Ω–Ω–æ–≥–æ —Ä–µ–π—Ç–∏–Ω–≥–∞ –†–æ—Å—Å–∏–∏ –Ω–µ –≤–ª–∏—è–µ...        1  \n",
       "1.6          –ë  –ò–Ω–¥–µ–∫—Å –≤–∫–ª—é—á–∞–µ—Ç –∞–∫—Ü–∏–∏ —Ç–æ–ª—å–∫–æ —Ç–µ—Ö —ç–º–∏—Ç–µ–Ω—Ç–æ–≤, –∫–æ...        1  \n",
       "1.7          –í  –ü—Ä–∏ –ø—Ä–æ–¥–∞–∂–µ –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω–æ–π –∞–∫—Ü–∏–∏ –¥–æ—Ö–æ–¥ –≤ —Ä—É–±–ª—è—Ö —Ä...        1  \n",
       "2.4          –ê  –í –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —Ç–æ—Ä–≥–æ–≤–ª–∏ –∞–∫—Ü–∏—è–º–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º ...        1  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 0.9545454545454546)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.correct.sum(), res_df.correct.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chapter\n",
       "1     1.00\n",
       "2     1.00\n",
       "3     1.00\n",
       "4     1.00\n",
       "5     1.00\n",
       "6     1.00\n",
       "7     1.00\n",
       "8     1.00\n",
       "9     1.00\n",
       "10    0.75\n",
       "11    0.75\n",
       "Name: correct, dtype: float64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.groupby(\"chapter\")['correct'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv('/Users/alfa/Code/financial_assistant/data/results/gpt4o-mini_rag.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4631c139a4b545c5bce1fa40e3a89e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "responses = []\n",
    "for question_dict in tqdm(questions):\n",
    "    response = get_rag_response(\n",
    "        question_dict,\n",
    "        prompt_template,\n",
    "        system_prompt,\n",
    "        db,\n",
    "    )\n",
    "    responses.append(response)\n",
    "    try:\n",
    "        response_text =  response.choices[0].message.content\n",
    "        if '{' not in response_text[:5]:\n",
    "            response_text = '{' + response_text\n",
    "        response_dict = json_repair.loads(response_text)\n",
    "\n",
    "        results.append(\n",
    "            question_dict | {\n",
    "                \"llm_answer\" : response_dict[\"answer\"],\n",
    "                \"llm_reasoning\" : response_dict[\"reasoning\"]\n",
    "            }\n",
    "        )\n",
    "    except Exception as e:\n",
    "        results.append({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 44 entries, 1.4 to 11.7\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   question       44 non-null     object\n",
      " 1   options        44 non-null     object\n",
      " 2   answer         44 non-null     object\n",
      " 3   chapter        44 non-null     int64 \n",
      " 4   llm_answer     44 non-null     object\n",
      " 5   llm_reasoning  44 non-null     object\n",
      " 6   correct        44 non-null     int64 \n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 2.8+ KB\n"
     ]
    }
   ],
   "source": [
    "res_df = pd.DataFrame(results).set_index(\"id\")\n",
    "res_df['correct'] = (res_df.answer == res_df.llm_answer).astype(int)\n",
    "res_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>options</th>\n",
       "      <th>answer</th>\n",
       "      <th>chapter</th>\n",
       "      <th>llm_answer</th>\n",
       "      <th>llm_reasoning</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.4</th>\n",
       "      <td>–õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å –∞–∫—Ü–∏–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏–∑—É–µ—Ç</td>\n",
       "      <td>[{'letter': '–ê', 'option_text': '–°–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∏...</td>\n",
       "      <td>–ê</td>\n",
       "      <td>1</td>\n",
       "      <td>–ê</td>\n",
       "      <td>–õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å –∞–∫—Ü–∏–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –µ—ë —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å—é...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5</th>\n",
       "      <td>–ß—Ç–æ –∏–∑ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω–æ–≥–æ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Ä–∏—Å–∫–æ–º –ø–æ –ø—Ä...</td>\n",
       "      <td>[{'letter': '–ê', 'option_text': '–†–∏—Å–∫ –∏–∑–º–µ–Ω–µ–Ω–∏...</td>\n",
       "      <td>–ê</td>\n",
       "      <td>1</td>\n",
       "      <td>–ê</td>\n",
       "      <td>–†–∏—Å–∫ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å—É–≤–µ—Ä–µ–Ω–Ω–æ–≥–æ —Ä–µ–π—Ç–∏–Ω–≥–∞ –†–æ—Å—Å–∏–π—Å–∫–æ–π...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.6</th>\n",
       "      <td>–í —Ñ–æ–Ω–¥–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å, —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º—ã–π –±–∏—Ä–∂–µ–π, –≤–∫–ª—é...</td>\n",
       "      <td>[{'letter': '–ê', 'option_text': '–í—Å–µ –∞–∫—Ü–∏–∏, –¥–æ...</td>\n",
       "      <td>–ë</td>\n",
       "      <td>1</td>\n",
       "      <td>–ë</td>\n",
       "      <td>–°–æ–≥–ª–∞—Å–Ω–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É, –∞–∫—Ü–∏–∏ –≤–∫–ª—é—á–∞—é—Ç—Å—è –≤ —Ñ–æ–Ω–¥–æ–≤—ã...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.7</th>\n",
       "      <td>–í —Å–ª—É—á–∞–µ, –µ—Å–ª–∏ –í—ã –∫—É–ø–∏–ª–∏ –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—É—é –∞–∫—Ü–∏—é –∑–∞ ...</td>\n",
       "      <td>[{'letter': '–ê', 'option_text': '500 —Ä—É–±–ª–µ–π.'}...</td>\n",
       "      <td>–í</td>\n",
       "      <td>1</td>\n",
       "      <td>–í</td>\n",
       "      <td>–ü—Ä–∏–±—ã–ª—å –æ—Ç –ø—Ä–æ–¥–∞–∂–∏ –∞–∫—Ü–∏–∏ –≤ –¥–æ–ª–ª–∞—Ä–∞—Ö —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.4</th>\n",
       "      <td>–í—ã –ø–æ–ª—É—á–∏–ª–∏ —É–±—ã—Ç–∫–∏ –æ—Ç —Å–æ–≤–µ—Ä—à–µ–Ω–∏—è —Å–¥–µ–ª–æ–∫ —Å –∞–∫—Ü–∏...</td>\n",
       "      <td>[{'letter': '–ê', 'option_text': '–ù–µ—Ç, –Ω–µ –≤–æ–∑–º–µ...</td>\n",
       "      <td>–ê</td>\n",
       "      <td>2</td>\n",
       "      <td>–ê</td>\n",
       "      <td>–í –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —É–∫–∞–∑–∞–Ω–æ, —á—Ç–æ —É–±—ã—Ç–∫–∏ –æ—Ç —Å–¥–µ–ª–æ–∫ —Å –∞–∫...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "id                                                       \n",
       "1.4                    –õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å –∞–∫—Ü–∏–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏–∑—É–µ—Ç   \n",
       "1.5  –ß—Ç–æ –∏–∑ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω–æ–≥–æ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Ä–∏—Å–∫–æ–º –ø–æ –ø—Ä...   \n",
       "1.6  –í —Ñ–æ–Ω–¥–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å, —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º—ã–π –±–∏—Ä–∂–µ–π, –≤–∫–ª—é...   \n",
       "1.7  –í —Å–ª—É—á–∞–µ, –µ—Å–ª–∏ –í—ã –∫—É–ø–∏–ª–∏ –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—É—é –∞–∫—Ü–∏—é –∑–∞ ...   \n",
       "2.4  –í—ã –ø–æ–ª—É—á–∏–ª–∏ —É–±—ã—Ç–∫–∏ –æ—Ç —Å–æ–≤–µ—Ä—à–µ–Ω–∏—è —Å–¥–µ–ª–æ–∫ —Å –∞–∫—Ü–∏...   \n",
       "\n",
       "                                               options answer  chapter  \\\n",
       "id                                                                       \n",
       "1.4  [{'letter': '–ê', 'option_text': '–°–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∏...      –ê        1   \n",
       "1.5  [{'letter': '–ê', 'option_text': '–†–∏—Å–∫ –∏–∑–º–µ–Ω–µ–Ω–∏...      –ê        1   \n",
       "1.6  [{'letter': '–ê', 'option_text': '–í—Å–µ –∞–∫—Ü–∏–∏, –¥–æ...      –ë        1   \n",
       "1.7  [{'letter': '–ê', 'option_text': '500 —Ä—É–±–ª–µ–π.'}...      –í        1   \n",
       "2.4  [{'letter': '–ê', 'option_text': '–ù–µ—Ç, –Ω–µ –≤–æ–∑–º–µ...      –ê        2   \n",
       "\n",
       "    llm_answer                                      llm_reasoning  correct  \n",
       "id                                                                          \n",
       "1.4          –ê  –õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å –∞–∫—Ü–∏–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –µ—ë —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å—é...        1  \n",
       "1.5          –ê  –†–∏—Å–∫ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å—É–≤–µ—Ä–µ–Ω–Ω–æ–≥–æ —Ä–µ–π—Ç–∏–Ω–≥–∞ –†–æ—Å—Å–∏–π—Å–∫–æ–π...        1  \n",
       "1.6          –ë  –°–æ–≥–ª–∞—Å–Ω–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É, –∞–∫—Ü–∏–∏ –≤–∫–ª—é—á–∞—é—Ç—Å—è –≤ —Ñ–æ–Ω–¥–æ–≤—ã...        1  \n",
       "1.7          –í  –ü—Ä–∏–±—ã–ª—å –æ—Ç –ø—Ä–æ–¥–∞–∂–∏ –∞–∫—Ü–∏–∏ –≤ –¥–æ–ª–ª–∞—Ä–∞—Ö —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç...        1  \n",
       "2.4          –ê  –í –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —É–∫–∞–∑–∞–Ω–æ, —á—Ç–æ —É–±—ã—Ç–∫–∏ –æ—Ç —Å–¥–µ–ª–æ–∫ —Å –∞–∫...        1  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 0.9545454545454546)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.correct.sum(), res_df.correct.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chapter\n",
       "1     1.00\n",
       "2     1.00\n",
       "3     1.00\n",
       "4     1.00\n",
       "5     1.00\n",
       "6     1.00\n",
       "7     1.00\n",
       "8     1.00\n",
       "9     1.00\n",
       "10    0.75\n",
       "11    0.75\n",
       "Name: correct, dtype: float64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.groupby(\"chapter\")['correct'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv('/Users/alfa/Code/financial_assistant/data/results/gpt4o_rag.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
